{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "import os\n",
    "import pandas as pd\n",
    "from arcgis import GIS\n",
    "import numpy as np\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# show all columns\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# pd.DataFrame.spatial.from_featureclass(???)\n",
    "# df.spatial.to_featureclass(location=???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store paths for input features\n",
    "gflu = r\"E:\\Projects\\Create_Residential_Capacity_Classes\\Inputs\\FutureLandUse2020.gdb\\FutureLandUse2020\"\n",
    "mag_policy = r\"E:\\Projects\\Create_Residential_Capacity_Classes\\Inputs\\MAG_Policy_REMM1.shp\"\n",
    "remm_parcels = r\"E:\\Projects\\Create_Residential_Capacity_Classes\\Inputs\\REMM.gdb\\Parcels_2015_utm12\"\n",
    "\n",
    "# create layers\n",
    "gflu_lyr = arcpy.MakeFeatureLayer_management(gflu,'gflu_lyr')\n",
    "mag_policy_lyr = arcpy.MakeFeatureLayer_management(mag_policy,'mag_policy_lyr')\n",
    "remm_parcels_lyr = arcpy.MakeFeatureLayer_management(remm_parcels,'remm_parcels_lyr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output gdb\n",
    "outputs = ['.\\\\Outputs', \"classes.gdb\"]\n",
    "gdb = os.path.join(outputs[0], outputs[1])\n",
    "if not arcpy.Exists(gdb):\n",
    "    arcpy.CreateFileGDB_management(outputs[0], outputs[1])\n",
    "\n",
    "outputs2 = ['.\\\\Outputs', \"scratch.gdb\"]    \n",
    "scratch = os.path.join(outputs2[0], outputs2[1])\n",
    "if not arcpy.Exists(scratch):\n",
    "    arcpy.CreateFileGDB_management(outputs2[0], outputs2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Single Family Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Family Parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select polygons that are designated as single family\n",
    "query = (''' GenLUType = 'Residential SF' ''')\n",
    "arcpy.SelectLayerByAttribute_management(gflu_lyr, 'NEW_SELECTION', query)\n",
    "sf_polys_wfrc = arcpy.FeatureClassToFeatureClass_conversion(gflu_lyr, scratch, '_01a_sf_polys_wfrc')\n",
    "\n",
    "query = (''' GenLUType = 'Residential' And MaxDUA < 8 ''')\n",
    "arcpy.SelectLayerByAttribute_management(mag_policy_lyr, 'NEW_SELECTION', query)\n",
    "sf_polys_mag = arcpy.FeatureClassToFeatureClass_conversion(mag_policy_lyr, scratch, '_01b_sf_polys_mag')\n",
    "\n",
    "# merge both land use layers\n",
    "sf_polys = arcpy.Merge_management([sf_polys_wfrc, sf_polys_mag], \n",
    "                                              os.path.join(scratch, '_01c_sf_polys'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>.\\Outputs\\scratch.gdb\\_01e_remm_parcels_sf_gflu_sj<h2>Messages</h2>Start Time: Tuesday, May 25, 2021 5:08:19 PM<br/>Succeeded at Tuesday, May 25, 2021 5:08:46 PM (Elapsed Time: 26.72 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result '.\\\\Outputs\\\\scratch.gdb\\\\_01e_remm_parcels_sf_gflu_sj'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = (''' parcel_acres > .05 And basebldg = 1 ''')\n",
    "arcpy.SelectLayerByAttribute_management(remm_parcels_lyr, 'NEW_SELECTION', query)\n",
    "\n",
    "# get sf remm parcels\n",
    "arcpy.SelectLayerByLocation_management(in_layer=remm_parcels_lyr, overlap_type=\"INTERSECT\",\n",
    "                                       select_features=sf_polys,\n",
    "                                       selection_type='SUBSET_SELECTION')\n",
    "\n",
    "remm_parcels_sf = arcpy.FeatureClassToFeatureClass_conversion(remm_parcels_lyr, scratch, '_01d_remm_parcels_sf')\n",
    "\n",
    "# spatial join to get new max dua\n",
    "target_features = remm_parcels_sf\n",
    "join_features = sf_polys\n",
    "output_features = os.path.join(scratch, \"_01e_remm_parcels_sf_gflu_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "# run the spatial join, use 'Join_Count' for number of units\n",
    "sj = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_ALL\", \n",
    "                           fieldmappings, \"HAVE_THEIR_CENTER_IN\")\n",
    "\n",
    "# calculate land value per acre\n",
    "arcpy.AddField_management(sj, 'lv_acre', 'FLOAT')\n",
    "arcpy.CalculateField_management(sj, field='lv_acre', expression=\"!land_value! / !parcel_acres!\", expression_type=\"PYTHON3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Land Value per Acre Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert parcels to points\n",
    "sf_pts = arcpy.management.FeatureToPoint(sj, os.path.join(scratch, \"_02a_sf_pts\"), \"INSIDE\")\n",
    "\n",
    "# create region wide fishnet\n",
    "env.outputCoordinateSystem = arcpy.SpatialReference(\"NAD 1983 UTM Zone 12N\")\n",
    "desc = arcpy.Describe(sf_polys)\n",
    "grid = arcpy.management.CreateFishnet(os.path.join(scratch, \"_02b_fishnet\"), \n",
    "                                str(desc.extent.lowerLeft), str(desc.extent.XMin) + \" \" + str(desc.extent.YMax + 10),\n",
    "                               \"300\",\"300\",\"0\",\"0\",str(desc.extent.upperRight),\"NO_LABELS\",\"#\",\"POLYGON\")\n",
    "\n",
    "grid_lyr = arcpy.MakeFeatureLayer_management(grid,'grid_lyr')\n",
    "arcpy.SelectLayerByLocation_management(in_layer=grid_lyr, overlap_type=\"INTERSECT\",                     \n",
    "                                       select_features=remm_parcels_sf,\n",
    "                                       selection_type='NEW_SELECTION')\n",
    "grid_subset = arcpy.FeatureClassToFeatureClass_conversion(grid_lyr, scratch, '_02b_fishnet2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spatial join to summarize land value per acre within each cell\n",
    "target_features = grid_subset\n",
    "join_features = sf_pts\n",
    "output_features = os.path.join(scratch,\"_02c_lv_acres_mean\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "# total market value\n",
    "fieldindex = fieldmappings.findFieldMapIndex('lv_acre')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'Mean'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join, use 'Join_Count' for number of units\n",
    "sj2 = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_ALL\", \n",
    "                           fieldmappings, \"INTERSECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create interpolated land value per acre\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "from arcpy.sa import *\n",
    "idw = r\".\\\\Outputs\\\\land_value_per_acre_idw.tif\"\n",
    "out_raster = Idw(sf_pts, \"lv_acre\", 100, 3, \"RadiusVariable(50)\"); \n",
    "out_raster.save(idw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>.\\Outputs\\scratch.gdb\\_02e_grid_no_samples<h2>Messages</h2>Start Time: Tuesday, May 25, 2021 5:09:44 PM<br/>Succeeded at Tuesday, May 25, 2021 5:09:45 PM (Elapsed Time: 0.22 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result '.\\\\Outputs\\\\scratch.gdb\\\\_02e_grid_no_samples'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate grids\n",
    "sj2_lyr = arcpy.MakeFeatureLayer_management(sj2,'sj2_lyr')\n",
    "\n",
    "# has data samples\n",
    "query = (''' Join_Count_1 >= 1 ''')\n",
    "arcpy.SelectLayerByAttribute_management(sj2_lyr, 'NEW_SELECTION', query)\n",
    "grid_has_samples = arcpy.FeatureClassToFeatureClass_conversion(sj2_lyr, scratch, '_02d_grid_has_samples')\n",
    "\n",
    "# does not have data samples\n",
    "query = (''' Join_Count_1 = 0 ''')\n",
    "arcpy.SelectLayerByAttribute_management(sj2_lyr, 'NEW_SELECTION', query)\n",
    "grid_no_samples = arcpy.FeatureClassToFeatureClass_conversion(sj2_lyr, scratch, '_02e_grid_no_samples')\n",
    "\n",
    "# add unique id to grid\n",
    "arcpy.AddField_management(grid_no_samples, 'unique_id', 'LONG')\n",
    "arcpy.CalculateField_management(grid_no_samples, field='unique_id', expression=\"!OBJECTID!\", expression_type=\"PYTHON3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>.\\\\Outputs\\zstats.csv<h2>Messages</h2>Start Time: Tuesday, May 25, 2021 5:09:45 PM<br/>Succeeded at Tuesday, May 25, 2021 5:09:45 PM (Elapsed Time: 0.09 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result '.\\\\\\\\Outputs\\\\zstats.csv'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run zonal stats\n",
    "zstats = r\".\\\\Outputs\\\\zstats.dbf\"\n",
    "ZonalStatisticsAsTable(grid_no_samples, 'unique_id', idw, zstats, \"DATA\", \"MEAN\")\n",
    "arcpy.TableToTable_conversion(zstats, r\".\\\\Outputs\", \"zstats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in tables\n",
    "grid_no_samples_sdf = pd.DataFrame.spatial.from_featureclass(grid_no_samples)\n",
    "grid_has_samples_sdf = pd.DataFrame.spatial.from_featureclass(grid_has_samples)\n",
    "zstats_df = pd.read_csv(os.path.join(r\".\\\\Outputs\", \"zstats.csv\"))\n",
    "\n",
    "# join zonal stats results to geometry\n",
    "grid_idw = grid_no_samples_sdf.merge(zstats_df, left_on='unique_id', right_on='unique_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Projects\\\\Create_Residential_Capacity_Classes\\\\Outputs\\\\scratch.gdb\\\\_02f_grid_idw'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format table\n",
    "grid_idw = grid_idw[['MEAN', 'SHAPE']].copy()\n",
    "grid_idw.columns = ['avg_lvacre', 'SHAPE']\n",
    "grid_idw['source'] = 'idw'\n",
    "\n",
    "grid_idw.spatial.to_featureclass(location=os.path.join(scratch, \"_02f_grid_idw\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format table\n",
    "grid_has_samples_sdf\n",
    "grid_has_samples_sdf = grid_has_samples_sdf[['lv_acre', 'SHAPE']].copy()\n",
    "grid_has_samples_sdf.columns = ['avg_lva', 'SHAPE']\n",
    "grid_has_samples_sdf['source'] = 'remm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the grid with samples with grid with interpolated\n",
    "lva_surface_sdf = pd.concat([grid_has_samples_sdf, grid_idw])\n",
    "lva_surface = lva_surface_sdf.spatial.to_featureclass(location=os.path.join(scratch, \"_02g_land_value_per_acre_surface\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Final Feature Class (polygons) and Bin using MaxDUA and Land Value per Acre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get land value per acre within gflu single family polygons (probably won't be used)\n",
    "target_features = sf_polys\n",
    "join_features = lva_surface\n",
    "output_features = os.path.join(scratch,\"_02h_sf__glfu_polygons_lva\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "# total market value\n",
    "fieldindex = fieldmappings.findFieldMapIndex('avg_lva')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'Mean'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join, use 'Join_Count' for number of units\n",
    "polygons = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_ALL\", \n",
    "                           fieldmappings, \"INTERSECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Projects\\\\Create_Residential_Capacity_Classes\\\\Outputs\\\\classes.gdb\\\\single_family_residential_polygons'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#==================\n",
    "# create dua bins\n",
    "#==================\n",
    "\n",
    "polygons_sdf = pd.DataFrame.spatial.from_featureclass(polygons)\n",
    "polygons_sdf = polygons_sdf[(polygons_sdf['MaxDUA'] > 0) & (polygons_sdf['avg_lva'] > 0)].copy()\n",
    "polygons_sdf = polygons_sdf[['OBJECTID_12','City','County','CityLUType','GenLUType','MaxDUA','PlanYear',\n",
    "                             'avg_lva','SHAPE']].copy()\n",
    "\n",
    "polygons_sdf['dua_group'] = None\n",
    "polygons_sdf.loc[(polygons_sdf['MaxDUA'] < 1.66), 'dua_group'] = \"a - estate\"\n",
    "polygons_sdf.loc[(polygons_sdf['MaxDUA'] >= 1.66)  & (polygons_sdf['MaxDUA'] < 3), 'dua_group'] = \"b - low intensity\"\n",
    "polygons_sdf.loc[(polygons_sdf['MaxDUA'] >= 3)  & (polygons_sdf['MaxDUA'] < 5), 'dua_group'] = \"c - traditional intensity\"\n",
    "polygons_sdf.loc[(polygons_sdf['MaxDUA'] >= 5)  & (polygons_sdf['MaxDUA'] < 8), 'dua_group'] = \"d - medium intensity\"\n",
    "polygons_sdf.loc[(polygons_sdf['MaxDUA'] >= 8), 'dua_group'] = \"e - high intensity\"\n",
    "\n",
    "#==================\n",
    "# create lva bins\n",
    "#==================\n",
    "\n",
    "polygons_sdf_a = polygons_sdf[polygons_sdf['dua_group'] == \"a - estate\"].copy()\n",
    "polygons_sdf_b = polygons_sdf[polygons_sdf['dua_group'] == \"b - low intensity\"].copy()\n",
    "polygons_sdf_c = polygons_sdf[polygons_sdf['dua_group'] == \"c - traditional intensity\"].copy()\n",
    "polygons_sdf_d = polygons_sdf[polygons_sdf['dua_group'] == \"d - medium intensity\"].copy()\n",
    "polygons_sdf_e = polygons_sdf[polygons_sdf['dua_group'] == \"e - high intensity\"].copy()\n",
    "\n",
    "polygons_sdf_a['Rank'] = polygons_sdf_a['avg_lva'].rank(pct = True)\n",
    "polygons_sdf_b['Rank'] = polygons_sdf_b['avg_lva'].rank(pct = True)\n",
    "polygons_sdf_c['Rank'] = polygons_sdf_c['avg_lva'].rank(pct = True)\n",
    "polygons_sdf_d['Rank'] = polygons_sdf_d['avg_lva'].rank(pct = True)\n",
    "polygons_sdf_e['Rank'] = polygons_sdf_e['avg_lva'].rank(pct = True)\n",
    "\n",
    "def calc_percentiles(table):\n",
    "    table['Percentile'] = None\n",
    "    table.loc[(table['Rank'] >= 0)  & (table['Rank'] < .20), 'Percentile'] = \"1 - 0-20\"\n",
    "    table.loc[(table['Rank'] >= .20)  & (table['Rank'] < .40), 'Percentile'] = \"2 - 20-40\"\n",
    "    table.loc[(table['Rank'] >= .40)  & (table['Rank'] < .60), 'Percentile'] = \"3 - 40-60\"\n",
    "    table.loc[(table['Rank'] >= .60)  & (table['Rank'] < .80), 'Percentile'] = \"4 - 60-80\"\n",
    "    table.loc[(table['Rank'] >= .80)  & (table['Rank'] <= 1), 'Percentile'] = \"5 - 80-100\"\n",
    "    return table[['OBJECTID_12', 'Rank', 'Percentile']].copy()\n",
    "\n",
    "polygons_sdf_a = calc_percentiles(polygons_sdf_a)\n",
    "polygons_sdf_b = calc_percentiles(polygons_sdf_b)\n",
    "polygons_sdf_c = calc_percentiles(polygons_sdf_c)\n",
    "polygons_sdf_d = calc_percentiles(polygons_sdf_d)\n",
    "polygons_sdf_e = calc_percentiles(polygons_sdf_e)\n",
    "\n",
    "polygons_sdf_abcde = pd.concat([polygons_sdf_a,polygons_sdf_b,polygons_sdf_c,polygons_sdf_d,polygons_sdf_e])\n",
    "polygons_sdf_classed = polygons_sdf.merge(polygons_sdf_abcde, left_on='OBJECTID_12', right_on='OBJECTID_12', how='inner')\n",
    "\n",
    "#======================\n",
    "# create category codes\n",
    "#======================\n",
    "\n",
    "polygons_sdf_classed['code'] = None\n",
    "polygons_sdf_classed['code'] = (polygons_sdf_classed['dua_group'].str.slice(0,1) + \n",
    "                                polygons_sdf_classed['Percentile'].str.slice(0,1))\n",
    "\n",
    "# export the polygons\n",
    "polygons_sdf_classed.spatial.to_featureclass(location=os.path.join(gdb, \"single_family_residential_polygons\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Final Feature Class (parcels) and Bin using MaxDUA and Land Value per Acre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get land value per acre within gflu single family polygons (probably won't be used)\n",
    "target_features = sj\n",
    "join_features = lva_surface\n",
    "output_features = os.path.join(scratch,\"_02i_sf_remm_parcels_lva\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "# total market value\n",
    "fieldindex = fieldmappings.findFieldMapIndex('avg_lva')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'Mean'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join, use 'Join_Count' for number of units\n",
    "parcels = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_ALL\", \n",
    "                           fieldmappings, \"INTERSECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Projects\\\\Create_Residential_Capacity_Classes\\\\Outputs\\\\classes.gdb\\\\single_family_residential_parcels'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#==================\n",
    "# create dua bins\n",
    "#==================\n",
    "\n",
    "parcels_sdf = pd.DataFrame.spatial.from_featureclass(parcels)\n",
    "parcels_sdf = parcels_sdf[(parcels_sdf['MaxDUA'] > 0) & (parcels_sdf['avg_lva'] > 0)].copy()\n",
    "parcels_sdf = parcels_sdf[['OBJECTID','city','county_name','CityLUType','GenLUType','MaxDUA','PlanYear',\n",
    "                             'avg_lva','SHAPE']].copy()\n",
    "\n",
    "parcels_sdf['dua_group'] = None\n",
    "parcels_sdf.loc[(parcels_sdf['MaxDUA'] < 1.66), 'dua_group'] = \"a - estate\"\n",
    "parcels_sdf.loc[(parcels_sdf['MaxDUA'] >= 1.66)  & (parcels_sdf['MaxDUA'] < 3), 'dua_group'] = \"b - low intensity\"\n",
    "parcels_sdf.loc[(parcels_sdf['MaxDUA'] >= 3)  & (parcels_sdf['MaxDUA'] < 5), 'dua_group'] = \"c - traditional intensity\"\n",
    "parcels_sdf.loc[(parcels_sdf['MaxDUA'] >= 5)  & (parcels_sdf['MaxDUA'] < 8), 'dua_group'] = \"d - medium intensity\"\n",
    "parcels_sdf.loc[(parcels_sdf['MaxDUA'] >= 8), 'dua_group'] = \"e - high intensity\"\n",
    "\n",
    "#==================\n",
    "# create lva bins\n",
    "#==================\n",
    "\n",
    "parcels_sdf_a = parcels_sdf[parcels_sdf['dua_group'] == \"a - estate\"].copy()\n",
    "parcels_sdf_b = parcels_sdf[parcels_sdf['dua_group'] == \"b - low intensity\"].copy()\n",
    "parcels_sdf_c = parcels_sdf[parcels_sdf['dua_group'] == \"c - traditional intensity\"].copy()\n",
    "parcels_sdf_d = parcels_sdf[parcels_sdf['dua_group'] == \"d - medium intensity\"].copy()\n",
    "parcels_sdf_e = parcels_sdf[parcels_sdf['dua_group'] == \"e - high intensity\"].copy()\n",
    "\n",
    "parcels_sdf_a['Rank'] = parcels_sdf_a['avg_lva'].rank(pct = True)\n",
    "parcels_sdf_b['Rank'] = parcels_sdf_b['avg_lva'].rank(pct = True)\n",
    "parcels_sdf_c['Rank'] = parcels_sdf_c['avg_lva'].rank(pct = True)\n",
    "parcels_sdf_d['Rank'] = parcels_sdf_d['avg_lva'].rank(pct = True)\n",
    "parcels_sdf_e['Rank'] = parcels_sdf_e['avg_lva'].rank(pct = True)\n",
    "\n",
    "def calc_percentiles(table):\n",
    "    table['Percentile'] = None\n",
    "    table.loc[(table['Rank'] >= 0)  & (table['Rank'] < .20), 'Percentile'] = \"1 - 0-20\"\n",
    "    table.loc[(table['Rank'] >= .20)  & (table['Rank'] < .40), 'Percentile'] = \"2 - 20-40\"\n",
    "    table.loc[(table['Rank'] >= .40)  & (table['Rank'] < .60), 'Percentile'] = \"3 - 40-60\"\n",
    "    table.loc[(table['Rank'] >= .60)  & (table['Rank'] < .80), 'Percentile'] = \"4 - 60-80\"\n",
    "    table.loc[(table['Rank'] >= .80)  & (table['Rank'] <= 1), 'Percentile'] = \"5 - 80-100\"\n",
    "    return table[['OBJECTID', 'Rank', 'Percentile']].copy()\n",
    "\n",
    "parcels_sdf_a = calc_percentiles(parcels_sdf_a)\n",
    "parcels_sdf_b = calc_percentiles(parcels_sdf_b)\n",
    "parcels_sdf_c = calc_percentiles(parcels_sdf_c)\n",
    "parcels_sdf_d = calc_percentiles(parcels_sdf_d)\n",
    "parcels_sdf_e = calc_percentiles(parcels_sdf_e)\n",
    "\n",
    "parcels_sdf_abcde = pd.concat([parcels_sdf_a,parcels_sdf_b,parcels_sdf_c,parcels_sdf_d,parcels_sdf_e])\n",
    "parcels_sdf_classed = parcels_sdf.merge(parcels_sdf_abcde, left_on='OBJECTID', right_on='OBJECTID', how='inner')\n",
    "\n",
    "#======================\n",
    "# create category codes\n",
    "#======================\n",
    "\n",
    "parcels_sdf_classed['code'] = None\n",
    "parcels_sdf_classed['code'] = (parcels_sdf_classed['dua_group'].str.slice(0,1) + \n",
    "                                parcels_sdf_classed['Percentile'].str.slice(0,1))\n",
    "\n",
    "# export the polygons\n",
    "parcels_sdf_classed.spatial.to_featureclass(location=os.path.join(gdb, \"single_family_residential_parcels\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Multi Family Classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joshPy3",
   "language": "python",
   "name": "joshpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
